{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T14:10:57.896344Z",
     "start_time": "2021-01-23T14:10:51.132239Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from datetime import datetime\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.datacamp.com/community/tutorials/fuzzy-string-python\n",
    "https://stackabuse.com/levenshtein-distance-and-text-similarity-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T15:25:10.613371Z",
     "start_time": "2021-01-13T15:25:10.138491Z"
    }
   },
   "outputs": [],
   "source": [
    "#Read all sheeets\n",
    "df= pd.read_excel(\"babbel2.xlsx\", sheet_name = None)\n",
    "\n",
    "df1 = df['vocab']\n",
    "df2 = df['REPP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T15:07:32.053628Z",
     "start_time": "2021-01-13T15:07:32.039261Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T14:59:06.468080Z",
     "start_time": "2021-01-13T14:59:06.451184Z"
    }
   },
   "outputs": [],
   "source": [
    "df.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T15:07:32.107414Z",
     "start_time": "2021-01-13T15:07:32.057140Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "df['REPP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T14:10:57.915331Z",
     "start_time": "2021-01-23T14:10:57.899529Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "str2Match = \"\"\n",
    "strOptions = [\"Apple Inc.\",\"apple park\",\"apple incorporated\",\"iphone\"]\n",
    "Ratios = process.extract(str2Match,strOptions)\n",
    "print(Ratios)\n",
    "# You can also select the string with the highest matching percentage\n",
    "highest = process.extractOne(str2Match,strOptions)\n",
    "print(highest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T14:11:18.668023Z",
     "start_time": "2021-01-23T14:11:18.560839Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in df['NORWEGIAN'].unique():\n",
    "    Ratios = process.extract(i,df.NORWEGIAN, limit = 10)\n",
    "    print(i, Ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T13:37:53.529559Z",
     "start_time": "2021-01-13T13:37:53.519500Z"
    }
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "Str1 = \"abonnere\"\n",
    "Str2 = \"abonnerte\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(Str1,Str2)\n",
    "Token_Set_Ratio = fuzz.token_set_ratio(Str1,Str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T13:37:53.923218Z",
     "start_time": "2021-01-13T13:37:53.916548Z"
    }
   },
   "outputs": [],
   "source": [
    "print(Ratio)\n",
    "print(Partial_Ratio)\n",
    "print(Token_Sort_Ratio)\n",
    "print(Token_Set_Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T17:13:18.411612Z",
     "start_time": "2021-02-21T17:13:10.227931Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T17:22:03.315608Z",
     "start_time": "2021-02-21T17:22:03.312122Z"
    }
   },
   "outputs": [],
   "source": [
    "import tabula\n",
    "from tabula import read_pdf\n",
    "pdf_path = \"/Users/Edite/NorwegianVocabulary.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T18:00:37.696726Z",
     "start_time": "2021-02-21T18:00:37.674679Z"
    }
   },
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfFileReader\n",
    "inputPdf = PdfFileReader(open(\"/Users/Edite/NorwegianVocabulary.pdf\", \"rb\"))\n",
    "docInfo = inputPdf.getDocumentInfo()\n",
    "docInfo.author\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T18:00:59.947712Z",
     "start_time": "2021-02-21T18:00:59.939492Z"
    }
   },
   "outputs": [],
   "source": [
    "docInfo.creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T18:01:02.385617Z",
     "start_time": "2021-02-21T18:01:02.378119Z"
    }
   },
   "outputs": [],
   "source": [
    "docInfo.producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T18:01:07.841833Z",
     "start_time": "2021-02-21T18:01:07.833466Z"
    }
   },
   "outputs": [],
   "source": [
    "docInfo.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T18:01:11.937836Z",
     "start_time": "2021-02-21T18:01:11.929470Z"
    }
   },
   "outputs": [],
   "source": [
    "docInfo.subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T18:01:27.881898Z",
     "start_time": "2021-02-21T18:01:27.634727Z"
    }
   },
   "outputs": [],
   "source": [
    "inputPdf.getNumPages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T17:51:23.546578Z",
     "start_time": "2021-02-21T17:51:23.497866Z"
    }
   },
   "outputs": [],
   "source": [
    "inputPdf.getPage(10).extractText()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:24:39.633003Z",
     "start_time": "2021-02-23T15:24:39.534725Z"
    }
   },
   "source": [
    "import csv\n",
    "norskI = []\n",
    "with open('NorwegianVocubulary.txt', 'r') as fd:\n",
    "    reader = csv.reader(fd)\n",
    "    for row in reader:\n",
    "        #print(str(row)[1:-1])\n",
    "        norskI.append(str(row)[1:-1])\n",
    "    norskI = ','.join(norskI)\n",
    "    print(norskI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T15:34:27.244978Z",
     "start_time": "2021-02-23T15:34:27.139757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chocolate', 'steak', 'avocado', 'koffee']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from foods import foods\n",
    "foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:32:59.233136Z",
     "start_time": "2021-02-23T16:32:59.227904Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:22:41.377311Z",
     "start_time": "2021-02-23T16:22:41.369794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T16:31:45.484121Z",
     "start_time": "2021-02-23T16:31:45.469933Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_valid_word(foods):\n",
    "    word = random.choice(foods)\n",
    "    while '-' in word or ' ' in word:\n",
    "        word = random.choice(foods)\n",
    "    return word.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-24T08:48:51.429012Z",
     "start_time": "2021-02-24T08:48:35.931477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have used these leters: \n",
      "Current word:  -------\n",
      "Type something:A\n",
      "\n",
      "You have used these leters: A\n",
      "Current word:  A---A--\n",
      "Type something:V\n",
      "\n",
      "You have used these leters: V A\n",
      "Current word:  AV--A--\n",
      "Type something:O\n",
      "\n",
      "You have used these leters: V A O\n",
      "Current word:  AVO-A-O\n",
      "Type something:C\n",
      "\n",
      "You have used these leters: V A C O\n",
      "Current word:  AVOCA-O\n",
      "Type something:D\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def hangman():\n",
    "    word = get_valid_word(foods)\n",
    "    word_letters = set(word)\n",
    "    alphabet = set(string.ascii_uppercase)\n",
    "    used_letters = set() \n",
    "    \n",
    "    while len(word_letters)>0:\n",
    "        print('You have used these leters:', ' '.join(used_letters))\n",
    "        word_list = [letter if letter in used_letters else '-' for letter in word]\n",
    "        \n",
    "        print('Current word: ', ''.join(word_list))\n",
    "        user_letter = input('Type something:').upper()\n",
    "        if user_letter in alphabet - used_letters:\n",
    "            used_letters.add(user_letter)\n",
    "            if user_letter in word_letters:\n",
    "                word_letters.remove(user_letter)\n",
    "                print('')\n",
    "        elif user_letter in used_letters:\n",
    "            print('You have already used that character. Please try again.')\n",
    "\n",
    "        else:\n",
    "            print('Invalid character. Please try again')\n",
    "            \n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    hangman()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
